{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ConfigFile.ipynb\n",
    "%run DB_Connection.ipynb\n",
    "\n",
    "import pyodbc\n",
    "import copy\n",
    "import math\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import ast\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Text preprocessing imports\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Logger SAAB (DEBUG)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a unique id with the help of current date timestamp\n",
    "st = datetime.fromtimestamp(time.time()).strftime('%d%m%Y%H%M%S')\n",
    "clientname=client_name['clientname']\n",
    "logging.basicConfig(filename=clientname+\"_\"+st+\".log\",level=logging.DEBUG,format=\"%(asctime)s:%(levelname)s:%(message)s\")\n",
    "logging.getLogger().setLevel(logging.DEBUG)\n",
    "logging.getLogger(clientname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "today_timestamp = datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    This function preprocesses the transcript column to remove punctuation, whitespaces and to lowercase & lemmatize them \n",
    "    Input:\n",
    "        data : the entire dataframe on which the preprocessing needs to be performed\n",
    "    Output:\n",
    "        preprocessed list of transcripts\n",
    "'''\n",
    "def preprocess_text(input_dataframe,target_column_number):\n",
    "    # Preprocessing text\n",
    "    lemmatized_text = []\n",
    "    count = 0\n",
    "    for row in input_dataframe.itertuples():\n",
    "#         print(row)\n",
    "        # Removing extra spaces, special characters and punctuation marks and lower casing the text\n",
    "        clean_text = re.sub(r'\\s\\s+',r' ',re.sub(r'[?|$|.|!|#|%|^|*|;|,|+|-|_|=|&]',r'',row[target_column_number].lower()))\n",
    "        # Lemmatizing the text\n",
    "        \n",
    "        lemmatized_text.append(\" \".join([str(token.lemma_).replace('-PRON-',str(token)) for token in nlp(str(clean_text))]))\n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script adherance check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    This function is for running through all the rows of the agent transcriptsad assign different script adherance scores\n",
    "    Input:\n",
    "        data : the entire dataframe on which the preprocessing needs to be performed\n",
    "    Output:\n",
    "        Series of scores of all the script adherance for each call\n",
    "'''\n",
    "def adherance_check(row_data,adherance):#row_data,\n",
    "    # Retrieving lsit of keywords for each kind of adherance\n",
    "    adherance_check_list = {}\n",
    "    for row in adherance.itertuples():\n",
    "        for section in ast.literal_eval(row[5]):\n",
    "            sections_score = {}\n",
    "            if(section=='Greetings'):\n",
    "                    row_data.split(\":\")[:5]\n",
    "            elif(section=='Closure'):\n",
    "                row_data.split(\":\")[5:]\n",
    "            for phrase in ast.literal_eval(row[5])[section]:\n",
    "                if phrase in row_data:\n",
    "                    sections_score[section] = 1\n",
    "\n",
    "        adherance_check_list[row[3]] = round(len(sections_score)/len(ast.literal_eval(row[5])),2)\n",
    "        \n",
    "    return adherance_check_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing to DW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Function to write the dataframe to DW\n",
    "  \n",
    "    Input :\n",
    "        script_adherance_df : dataframe that consists of scores of the scripte adherance checks for each call\n",
    "            \n",
    "'''\n",
    "def write_df_to_dw(script_adherance_df):\n",
    "    # Writing to DW\n",
    "    today_timestamp = datetime.now()\n",
    "    server = 'saab-server-resource.database.windows.net'\n",
    "    database = 'SAAB_DW_Resource'\n",
    "    username = 'saabadmin'\n",
    "    password = 'p@$$w0rd'\n",
    "    conn = pyodbc.connect('DRIVER={ODBC Driver 13 for SQL Server};SERVER='+server+';DATABASE='+database+';UID='+username+';PWD='+ password)\n",
    "    cursor = conn.cursor()\n",
    "    id_count = 0\n",
    "    for index,row in script_adherance_df.iterrows():\n",
    "        id_count += 1\n",
    "        cursor.execute(\"INSERT INTO [dbo].[SAAB_ML_SCRIPT_ADHERANCE_FT]([RESULT_ID],[DOMAIN_ID],[SCRIPT_ID],[CALL_ID],[SCORE],[CREATED_DATE],[CREATED_BY]) values (?, ?, ?, ?, ?, ?, ?)\", id_count, row['DOMAIN_ID'], row['SCRIPT_ID'], row['CALL_ID'], row['SCORE'],row['CREATED_DATE'],row['CREATED_BY']) \n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    logging.debug(\"Starting....\")\n",
    "    try:\n",
    "        domain_id = 101\n",
    "        logging.debug(\"Reading Data in progress....\")\n",
    "        raw_transcript_data = fetch_data(\"select * from [dbo].[Fact_Audio_Insights] order by [Call_ID],[StartTime];\")\n",
    "        agent_label_data = fetch_data(\"select * from [dbo].[SAAB_ML_SPEAKER_MAPPING_FT] order by Result_ID\")\n",
    "        adherance_data = fetch_data(\"select * from [dbo].[SAAB_ML_MASTER_SCRIPT_ADHERANCE_DM] where DOMAIN_ID = \" + str(domain_id))\n",
    "    except Exception as err:\n",
    "        if \"Could not open a connection to SQL Server\" in str(err):\n",
    "            logging.error(\"Could not connect to data warehouse : \"+str(err.args)+\"\\nTraceback :\"+str(err.with_traceback))\n",
    "        else:\n",
    "            logging.error(\"Error occured with database :\"+str(err.args)+\"\\nTraceback :\"+str(err.with_traceback))\n",
    "        sys.exit(1)\n",
    "    try:\n",
    "        domain_id = 101\n",
    "        created_by = \"MDXC\"\n",
    "        # Assign respective agent and customer transcripts\n",
    "        for row in agent_label_data.itertuples():\n",
    "            agent_label_data.loc[row[0],'Transcripts'] = \":\".join(list(raw_transcript_data[((raw_transcript_data['Call_ID']==row[2]) & (raw_transcript_data['SpeakerId']==row[4]))].Display))\n",
    "            \n",
    "        # Preprocess transcripts\n",
    "        logging.debug(\"Preprocessing in progress....\")\n",
    "        agent_label_data['Lemmatized_Transcript']  = preprocess_text(agent_label_data,10)\n",
    "        \n",
    "        # Scoring for script adherance\n",
    "        agent_label_data['Adherance_Scores'] = np.where(agent_label_data['LABEL']=='A',agent_label_data['Lemmatized_Transcript'].apply(adherance_check,adherance=adherance_data),\"\")\n",
    "        \n",
    "        # Preparing final script sdherance dataframe\n",
    "        logging.debug(\"Script Adherance check in progress....\")\n",
    "        script_ft_df = pd.concat([pd.DataFrame(agent_label_data[agent_label_data['LABEL']=='A'].DOMAIN_ID),pd.DataFrame(agent_label_data[agent_label_data['LABEL']=='A'].CALL_ID),agent_label_data[agent_label_data['LABEL']=='A'].Adherance_Scores.apply(pd.Series)],axis=1)\n",
    "        script_ft_df = script_ft_df.melt(id_vars=[\"DOMAIN_ID\",\"CALL_ID\"], var_name=\"SCRIPT_ID\",value_name=\"SCORE\").sort_values('CALL_ID')\n",
    "        script_ft_df['CREATED_DATE'] = today_timestamp\n",
    "        script_ft_df['CREATED_BY'] = created_by\n",
    "        \n",
    "        # Writing dataframe to DW\n",
    "        logging.debug(\"Writing to DW in progress....\")\n",
    "        write_df_to_dw(script_ft_df)\n",
    "        \n",
    "    except Exception as err:\n",
    "        logging.error(\"Error occured : \"+str(err.args)+\"\\nTraceback :\"+str(err.with_traceback))\n",
    "        sys.exit(1)\n",
    "    finally:\n",
    "        logging.debug(\"End of script adherance check\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
