{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ConfigFile.ipynb\n",
    "%run DB_Connection.ipynb\n",
    "\n",
    "import pyodbc\n",
    "import copy\n",
    "import math\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "from io import StringIO\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Logger SAAB (DEBUG)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a unique id with the help of current date timestamp\n",
    "st = datetime.fromtimestamp(time.time()).strftime('%d%m%Y%H%M%S')\n",
    "clientname=client_name['clientname']\n",
    "logging.basicConfig(filename=clientname+\"_\"+st+\".log\",level=logging.DEBUG,format=\"%(asctime)s:%(levelname)s:%(message)s\")\n",
    "logging.getLogger().setLevel(logging.DEBUG)\n",
    "logging.getLogger(clientname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "today_timestamp = datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    This function is for running through all the rows of the preprocessed transcripts per call and create bigrams\n",
    "    Input:\n",
    "        data : each row data having preprocessed transcript\n",
    "    Output:\n",
    "        bigrams for the preprocessed transcript\n",
    "'''\n",
    "def bigram_generation(row_data):\n",
    "    bigram = []\n",
    "    for i in nltk.bigrams(row_data.split()):\n",
    "#         print (i)\n",
    "        bigram.append(\" \".join(i) )\n",
    "#     print(bigram)\n",
    "#     print(\"****\")\n",
    "    return str(bigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    This function is for running through all the rows of the preprocessed transcripts per call and create trigrams\n",
    "    Input:\n",
    "        data : each row data having preprocessed transcript\n",
    "    Output:\n",
    "        trigrams for the preprocessed transcript\n",
    "'''\n",
    "def trigram_generation(row_data):\n",
    "    trigram = []\n",
    "    for i in ngrams(row_data,3):\n",
    "#         print (i)\n",
    "        trigram.append(\" \".join(i) )\n",
    "#     print(str(trigram))\n",
    "#     print(type(str(trigram)))\n",
    "#     print(\"****\")\n",
    "    return str(trigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing to DW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Function to write the dataframe to DW\n",
    "  \n",
    "    Input :\n",
    "        word_count_df : dataframe that consists of unigrams, bigrams and trigrams of the preprocessed transcript for each call\n",
    "            \n",
    "'''\n",
    "def write_df_to_dw(word_count_df):\n",
    "    # Writing to DW\n",
    "    today_timestamp = datetime.now()\n",
    "    server = mysql['server']\n",
    "    database = mysql['database']\n",
    "    username = mysql['username']\n",
    "    password = mysql['password']\n",
    "    conn = pyodbc.connect('DRIVER={ODBC Driver 13 for SQL Server};SERVER='+server+';DATABASE='+database+';UID='+username+';PWD='+ password)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.setinputsizes([(pyodbc.SQL_INTEGER,), (pyodbc.SQL_INTEGER,),(pyodbc.SQL_INTEGER,),(pyodbc.SQL_WVARCHAR,20,0),(pyodbc.SQL_WVARCHAR,0), (pyodbc.SQL_TYPE_TIMESTAMP), (pyodbc.SQL_WVARCHAR,50,0)])\n",
    "    id_count = 0\n",
    "    for index,row in word_count_df.iterrows():\n",
    "        id_count += 1\n",
    "        cursor.execute(\"INSERT INTO [dbo].[SAAB_ML_WORDCOUNT_FT]([RESULT_ID], [CALL_ID], [DOMAIN_ID], [TRANSCRIPT_TYPE], [TRANSCRIPT], [CREATED_DATE], [CREATED_BY]) values (?, ?, ?, ?, ?, ?, ?)\", id_count, row['Call_ID'], row['Domain_ID'], row['Transcript_Type'], row['Transcript'],  today_timestamp, row['Created_By'])\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    logging.debug(\"Starting....\")\n",
    "    try:\n",
    "        domain_id = 101\n",
    "        created_by = \"MDXC\"\n",
    "        top_level_container = \"preprocessed-transcripts\"\n",
    "\n",
    "        # Fetch the blob from the preprocessed container\n",
    "        blob_file = fetch_data_from_blob(top_level_container)\n",
    "        preprocessed_data = pd.read_csv(StringIO(blob_file)) \n",
    "        \n",
    "    except Exception as err:\n",
    "        logging.error(\"Error occured while connecting to storage account :\"+str(err.args)+\"\\nTraceback :\"+str(err.with_traceback))\n",
    "        sys.exit(1)\n",
    "    try:\n",
    "        preprocessed_data['Preprocessed Transcripts'] = preprocessed_data['Preprocessed Transcripts'].apply(lambda x : \" \".join(x.replace(\"'\",\"\").replace(\"_\",\" \").strip('][').split(', ') ))\n",
    "        # Extracting unigrams\n",
    "        logging.debug(\"Creation of unigrams in progress....\")\n",
    "        preprocessed_data['Unigrams'] = preprocessed_data['Preprocessed Transcripts'].apply(lambda x : (x.split(\" \")))\n",
    "\n",
    "        # Extracting bigrams\n",
    "        logging.debug(\"Creation of bigrams in progress....\")\n",
    "        preprocessed_data['Bigrams'] = preprocessed_data['Preprocessed Transcripts'].apply(bigram_generation)\n",
    "\n",
    "        # Extracting trigrams\n",
    "        logging.debug(\"Creation of trigrams in progress....\")\n",
    "        preprocessed_data['Trigrams'] = preprocessed_data['Unigrams'].apply(trigram_generation)\n",
    "        preprocessed_data  = preprocessed_data[['Call_ID','Unigrams','Bigrams','Trigrams']]\n",
    "\n",
    "        preprocessed_data = preprocessed_data.melt(id_vars=[\"Call_ID\"], var_name=[\"Transcript_Type\"],value_name=\"Transcript\").sort_values('Call_ID')\n",
    "        preprocessed_data['Domain_ID'] = domain_id\n",
    "        preprocessed_data['Created_By'] = created_by\n",
    "        \n",
    "        # Changing datatype before writing to DW\n",
    "        preprocessed_data['Transcript'] = preprocessed_data['Transcript'].astype(str)\n",
    "\n",
    "        \n",
    "        # Writing to DW\n",
    "        logging.debug(\"Writing to DW in progress....\")\n",
    "        preprocessed_data = write_df_to_dw(preprocessed_data)\n",
    "#         print(preprocessed_data)\n",
    "    except Exception as err:\n",
    "        logging.error(\"Error occured : \"+str(err.args)+\"\\nTraceback :\"+str(err.with_traceback))\n",
    "        sys.exit(1)\n",
    "    finally:\n",
    "        logging.error(\"End of word count creation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG - Starting....\n",
      "DEBUG - Starting new HTTPS connection (1): saabstorageresource.blob.core.windows.net:443\n",
      "DEBUG - https://saabstorageresource.blob.core.windows.net:443 \"GET /preprocessed-transcripts?restype=container&comp=list HTTP/1.1\" 200 None\n",
      "DEBUG - https://saabstorageresource.blob.core.windows.net:443 \"GET /preprocessed-transcripts/Preprocessed_Transcripts_29012020161128.csv HTTP/1.1\" 206 170282\n",
      "DEBUG - Creation of unigrams in progress....\n",
      "DEBUG - Creation of bigrams in progress....\n",
      "DEBUG - Creation of trigrams in progress....\n",
      "DEBUG - Writing to DW in progress....\n",
      "ERROR - End of word count creation\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
