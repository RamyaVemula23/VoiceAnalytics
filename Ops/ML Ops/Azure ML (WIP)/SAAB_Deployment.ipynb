{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found workspace saab_ml_workspace at location westus2\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.authentication import ServicePrincipalAuthentication\n",
    "from azureml.core import Workspace\n",
    "svc_pr_password = \"sWR5y]ocjTTMxT@7H13YXWFRcss=.nrN\"\n",
    "\n",
    "svc_pr = ServicePrincipalAuthentication(\n",
    "    tenant_id=\"93f33571-550f-43cf-b09f-cd331338d086\",\n",
    "    service_principal_id=\"0a89e69e-7aae-4a80-8b76-7dc9f65c3d16\",\n",
    "    service_principal_password=svc_pr_password)\n",
    "\n",
    "\n",
    "ws = Workspace(\n",
    "    subscription_id=\"047ae087-7d35-4c57-8fe9-7a442cc9cf16\",\n",
    "    resource_group=\"Speech_Analytics\",\n",
    "    workspace_name=\"saab_ml_workspace\",\n",
    "    auth=svc_pr\n",
    "    )\n",
    "\n",
    "print(\"Found workspace {} at location {}\".format(ws.name, ws.location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##from azureml.core import Workspace\n",
    "##ws = Workspace.from_config(path=\".\\config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model topic_model\n"
     ]
    }
   ],
   "source": [
    "topic_model = Model.register(workspace=ws,\n",
    "                       model_name=\"topic_model\",\n",
    "                       model_path=\"Topic_Modelling.pkl\", # local path\n",
    "                       description=\"A_topic_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model topic_prediction_model\n"
     ]
    }
   ],
   "source": [
    "topic_prediction_model = Model.register(workspace=ws,\n",
    "                       model_name=\"topic_prediction_model\",\n",
    "                       model_path=\"Topic_Prediction.pkl\", # local path\n",
    "                       description=\"A_topic_prediction_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved dependency info in env.yml\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "# Add the dependencies for your model\n",
    "myenv = CondaDependencies()\n",
    "myenv.add_conda_package(\"gensim\")\n",
    "myenv.add_conda_package(\"pyodbc\")\n",
    "myenv.add_conda_package(\"gensim\")\n",
    "myenv.add_conda_package(\"scikit-learn\")\n",
    "myenv.add_conda_package(\"time\")\n",
    "\n",
    "# Save the environment config as a .yml file\n",
    "env_file = 'env.yml'\n",
    "with open(env_file,\"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())\n",
    "print(\"Saved dependency info in\", env_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "classifier_inference_config = InferenceConfig(runtime= \"python\",\n",
    "                                              entry_script=\"score.py\",\n",
    "                                              conda_file=\"env.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating..............................................................................................................................................................................\n",
      "SucceededProvisioning operation finished, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AksCompute\n",
    "\n",
    "cluster_name = 'aks-cluster-run'\n",
    "compute_config = AksCompute.provisioning_configuration(location='westus')\n",
    "production_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "production_cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AksWebservice,AciWebservice\n",
    "\n",
    "classifier_deploy_config = AksWebservice.deploy_configuration(cpu_cores = 1,\n",
    "                                                              memory_gb = 3.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'production_cluster' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-15fdb97a1bc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m                        \u001b[0minference_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier_inference_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                        \u001b[0mdeployment_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier_deploy_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                        deployment_target = production_cluster)\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_deployment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshow_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'production_cluster' is not defined"
     ]
    }
   ],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "topic_model = ws.models['topic_model']\n",
    "#topic_prediction_model = ws.models['topic_prediction_model']\n",
    "service = Model.deploy(workspace=ws,\n",
    "                       name = 'topic-model-service_v2',\n",
    "                       models = [topic_model],\n",
    "                       inference_config = classifier_inference_config,\n",
    "                       deployment_config = classifier_deploy_config,\n",
    "                       deployment_target = production_cluster)\n",
    "service.wait_for_deployment(show_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-19T06:52:49,791146660+00:00 - gunicorn/run \n",
      "/bin/bash: /azureml-envs/azureml_b577801dabfe2a395022a8230bbcddea/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "/bin/bash: /azureml-envs/azureml_b577801dabfe2a395022a8230bbcddea/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "/bin/bash: /azureml-envs/azureml_b577801dabfe2a395022a8230bbcddea/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "2020-02-19T06:52:49,793510969+00:00 - iot-server/run \n",
      "2020-02-19T06:52:49,795233776+00:00 - nginx/run \n",
      "/usr/sbin/nginx: /azureml-envs/azureml_b577801dabfe2a395022a8230bbcddea/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_b577801dabfe2a395022a8230bbcddea/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_b577801dabfe2a395022a8230bbcddea/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_b577801dabfe2a395022a8230bbcddea/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_b577801dabfe2a395022a8230bbcddea/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/bin/bash: /azureml-envs/azureml_b577801dabfe2a395022a8230bbcddea/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "2020-02-19T06:52:49,812961943+00:00 - rsyslog/run \n",
      "bash: /azureml-envs/azureml_b577801dabfe2a395022a8230bbcddea/lib/libtinfo.so.5: no version information available (required by bash)\n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "/bin/bash: /azureml-envs/azureml_b577801dabfe2a395022a8230bbcddea/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "2020-02-19T06:52:49,868934157+00:00 - iot-server/finish 1 0\n",
      "2020-02-19T06:52:49,870086062+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 19.9.0\n",
      "Listening at: http://127.0.0.1:31311 (10)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 41\n",
      "Initialized PySpark session.\n",
      "Initializing logger\n",
      "Starting up app insights client\n",
      "Starting up request id generator\n",
      "Starting up app insight hooks\n",
      "Invoking user's init function\n",
      "2020-02-19 06:52:52,564 | azureml.core.run | DEBUG | Could not load run context RunEnvironmentException:\n",
      "\tMessage: Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\n",
      "\tInnerException None\n",
      "\tErrorResponse \n",
      "{\n",
      "    \"error\": {\n",
      "        \"message\": \"Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\"\n",
      "    }\n",
      "}, switching offline: False\n",
      "2020-02-19 06:52:52,564 | azureml.core.run | DEBUG | Could not load the run context and allow_offline set to False\n",
      "2020-02-19 06:52:52,564 | azureml.core.model | DEBUG | Using passed in version 5\n",
      "2020-02-19 06:52:52,564 | azureml.core.model | DEBUG | Found model path at azureml-models/topic_model/5/Topic_Modelling.pkl\n",
      "/azureml-envs/azureml_b577801dabfe2a395022a8230bbcddea/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "Users's init has completed successfully\n",
      "Scoring timeout setting is not found. Use default timeout: 3600000 ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /azureml-envs/azureml_70a2c3d7a8499f813c46b5380ccf2421/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "/bin/bash: /azureml-envs/azureml_70a2c3d7a8499f813c46b5380ccf2421/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "/bin/bash: /azureml-envs/azureml_70a2c3d7a8499f813c46b5380ccf2421/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "/bin/bash: /azureml-envs/azureml_70a2c3d7a8499f813c46b5380ccf2421/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "bash: /azureml-envs/azureml_70a2c3d7a8499f813c46b5380ccf2421/lib/libtinfo.so.5: no version information available (required by bash)\n",
      "2020-02-18T17:16:05,929669532+00:00 - rsyslog/run \n",
      "2020-02-18T17:16:05,929741132+00:00 - gunicorn/run \n",
      "2020-02-18T17:16:05,931304633+00:00 - iot-server/run \n",
      "2020-02-18T17:16:05,932393334+00:00 - nginx/run \n",
      "/usr/sbin/nginx: /azureml-envs/azureml_70a2c3d7a8499f813c46b5380ccf2421/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_70a2c3d7a8499f813c46b5380ccf2421/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_70a2c3d7a8499f813c46b5380ccf2421/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_70a2c3d7a8499f813c46b5380ccf2421/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_70a2c3d7a8499f813c46b5380ccf2421/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "/bin/bash: /azureml-envs/azureml_70a2c3d7a8499f813c46b5380ccf2421/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "2020-02-18T17:16:06,005400783+00:00 - iot-server/finish 1 0\n",
      "2020-02-18T17:16:06,006576483+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 19.9.0\n",
      "Listening at: http://127.0.0.1:31311 (12)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 39\n",
      "Initialized PySpark session.\n",
      "Failed to load or parse file /root/.azureml/auth/azureProfile.json. It will be overridden by default settings.\n",
      "Failed to load or parse file /root/.azureml/auth/az.json. It will be overridden by default settings.\n",
      "Failed to load or parse file /root/.azureml/auth/az.sess. It will be overridden by default settings.\n",
      "Failed to load or parse file /root/.azure/azureProfile.json. It will be overridden by default settings.\n",
      "Performing interactive authentication. Please follow the instructions on the terminal.\n",
      "Detect no GUI is available, so fall back to device code\n",
      "f1c1cd56-4d8d-4936-898a-bffa4f5a5fa4 - CodeRequest:Getting user code info.\n",
      "To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code BTP973PZD to authenticate.\n",
      "f1c1cd56-4d8d-4936-898a-bffa4f5a5fa4 - TokenRequest:Getting a token via device code\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
